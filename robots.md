`robots.txt` permet de définir des règles d'indexation pour les moteurs de recherche (attention ses règles sont publiques et ne sont pas toujours respectées).

C'est également dans ce fichier qu'on déclare le `sitemap.xml` du site.

`humans.txt` est le pendant de robots.txt dans lequel on peut renseigner des informations telles que les technologies ou les logiciels employées, ou encore les participants au projet. C'est un espace libre.

 - http://www.robotstxt.org/
 - http://www.humanstxt.org/